# agent.pyï¼ˆå®Œæ•´ç‰ˆï¼‰
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–DeepSeek LLM
llm = ChatOpenAI(
    model="deepseek-chat",
    openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
    openai_api_base="https://api.deepseek.com/v1",
    temperature=0.7,
    max_tokens=1000
)

# åˆ›å»ºè®°å¿†ï¼ˆç”¨äºè®°ä½å¯¹è¯å†å²ï¼‰
memory = ConversationBufferMemory()

# åˆ›å»ºå¯¹è¯é“¾
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True  # æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹
)

print("="*50)
print("ğŸ¤– DeepSeek Agent å·²å¯åŠ¨ï¼")
print("æ”¯æŒåŠŸèƒ½ï¼š")
print("  - è‡ªç”±å¯¹è¯")
print("  - è®°å¿†ä¸Šä¸‹æ–‡")
print("  - è¿ç»­å¯¹è¯")
print("è¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯")
print("="*50)

# å¯¹è¯å¾ªç¯
while True:
    user_input = input("\nä½ : ")
    
    if user_input.lower() in ['é€€å‡º', 'exit', 'quit']:
        print("ğŸ‘‹ å†è§ï¼")
        break
    
    try:
        # è·å–AIå“åº”
        response = conversation.predict(input=user_input)
        print(f"\nAgent: {response}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")